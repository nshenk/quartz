---
title: "Neural Espionage"
---

I recently had a conversation with a friend and prolific Twitter user who said he had trained GPT-3.5 on all of his tweets, and then talked to it. The fine-tuned LLM generated ideas that my friend had had before, but had never written down anywhere. I recently had a similar experience with my own Twitter account. Spooky to say the least.



Imagine the intelligence implications of this technology. Given a large enough corpus of genuine text from someone, you can essentially use AI to get into their head. You can extract beliefs and ideas from their brain without ever interacting with them directly.  



This technology could be used learn about a person of interest on an intimate level. It could help the operator take their sales meeting prep to a new level. It could be used to social engineer someone in a cyber attack. Or to have next-generation parasocial relationships. It could even be used to commit thought-theft - a future crime where the attacker steals thoughts or ideas from the victim's mind (i.e. sensitive secrets). 



One defense against this is obviously to never post anything on the internet. If you do, make sure it's not your genuine thoughts. And if you must post your genuine thoughts, make sure you're interleaving some disinformation (i.e. insincere thoughts). Still, there are other (slightly more difficult) ways to get in your head - maybe you use the notes app on your phone, or you have genuine conversations with others (that can be secretly recorded), or you talk out loud to yourself (which can be secretly recorded). Anyways, I'm very excited to watch (and possibly participate in) the burgeoning new field of neural espionage.