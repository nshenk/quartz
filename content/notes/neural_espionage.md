---
title: "Neural Espionage"
---

I recently had a conversation with a friend and prolific Twitter user who said he had trained GPT-3.5 on all of his tweets, and then talked to it. The fine-tuned LLM generated ideas that my friend had had before, but had never written down anywhere. I recently had a similar experience with my own Twitter account. Spooky to say the least.



Now imagine the intelligence implications of this technology. Given a large enough corpus of genuine text from someone, you can essentially use AI to get into their head. You can extract beliefs and ideas from their brain without ever interacting with them directly.  



This technology could be used to take sales call prep to a new level. It could be used to social engineer someone in a cyber attack. It could be used to have next-generation parasocial relationships. It could even be used to commit thought-theft - a future crime where the attacker steals thoughts or ideas from the victim's mind (i.e. sensitive secrets). 



One defense against this is obviously to never post anything on the internet. If you do, make sure it's not your genuine thoughts. And if you must post your genuine thoughts, make sure you're interleaving some disinformation (i.e. insincere thoughts). I'm very excited to watch (and maybe participate in) the burgeoning new field of neural espionage.