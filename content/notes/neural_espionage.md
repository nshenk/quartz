---
title: "Neural Espionage"
---

I recently had a conversation with a friend and prolific Twitter user who said he had trained GPT-3.5 on all of his tweets, and then talked to it. The fine-tuned Large Language Model (LLM) generated ideas that he had had before, but had never written down anywhere. I recently had a similar experience using my own writing as training material. Spooky to say the least.



Imagine the intelligence implications of this technique. Given a large enough corpus of genuine text from an individual, you can essentially get into their head remotely by simply fine-tuning an LLM. You can extract beliefs and ideas from their brain without ever interacting with them directly, and without them knowing.  



This technology could be used learn about a person of interest on an intimate level. It could help the operator take their sales meeting prep to a new level. It could be used to social engineer someone in a cyber attack. Or to have next-generation parasocial relationships. It could even be used to commit thought-theft — a future crime where the attacker steals thoughts or ideas from the victim's mind (i.e. sensitive secrets). 



One defense against this is obviously to never post anything on the internet. If you do, make sure they're not your genuine thoughts. And if you must post your genuine thoughts, make sure you're interleaving some disinformation (i.e. insincere thoughts) throughout. Still, there are other (slightly more difficult) ways to get in your head - maybe you use the notes app on your phone (which can be accessed via spyware among other ways), or you are genuine in your texts (which can be accessed via spyware among other ways), or you have genuine conversations with others (which can be secretly recorded), or you talk out loud to yourself (which can be secretly recorded). 

Anyways, I'm very excited to watch — and possibly (ethically) participate in — the burgeoning new field of neural espionage.
